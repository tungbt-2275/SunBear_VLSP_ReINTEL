{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5osAcCvGl9g"
   },
   "source": [
    "# DEALING WITH META DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a_WeMeGcGl9h"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"path_to_train_data\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1793,
     "status": "ok",
     "timestamp": 1607484418938,
     "user": {
      "displayName": "Tùng Bùi",
      "photoUrl": "",
      "userId": "07889802812406437747"
     },
     "user_tz": -420
    },
    "id": "R9ACHW0tGl9p",
    "outputId": "f18d1008-c8d5-42c0-a528-a292d1a05488"
   },
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7CLnn8yG_HPx"
   },
   "outputs": [],
   "source": [
    "# Fill missing values\n",
    "\n",
    "train_data[\"post_message\"] = train_data[\"post_message\"].fillna(\"\")\n",
    "train_data = train_data.fillna(0)\n",
    "\n",
    "train_data = train_data[pd.to_numeric(train_data['timestamp_post'], errors='coerce').notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 943
    },
    "executionInfo": {
     "elapsed": 1453,
     "status": "ok",
     "timestamp": 1607484440761,
     "user": {
      "displayName": "Tùng Bùi",
      "photoUrl": "",
      "userId": "07889802812406437747"
     },
     "user_tz": -420
    },
    "id": "PFwoeNX_ZQsH",
    "outputId": "d3d0cecc-d903-4292-829d-8529c69fbe16"
   },
   "outputs": [],
   "source": [
    "# correct some features\n",
    "def preprocess(x):\n",
    "    x = str(x)\n",
    "    try:\n",
    "        x = x.split()[0]\n",
    "        x = int(x)\n",
    "    except:\n",
    "        x = 0\n",
    "    return x\n",
    "\n",
    "train_data[\"timestamp_post\"] = train_data[\"timestamp_post\"].astype(float)\n",
    "train_data[\"num_like_post\"] = train_data[\"num_like_post\"].apply(lambda x: preprocess(x)) \n",
    "train_data[\"num_share_post\"] = train_data[\"num_share_post\"].apply(lambda x: preprocess(x)) \n",
    "train_data[\"num_comment_post\"] = train_data[\"num_comment_post\"].apply(lambda x: preprocess(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ffFeHOiQGl9s"
   },
   "outputs": [],
   "source": [
    "# Get feature from images\n",
    "\n",
    "def get_num_image(id):\n",
    "    img_path = os.path.join(\"public_train_final_images\", str(id))\n",
    "    try:\n",
    "        num_image = len(os.listdir(img_path))\n",
    "    except:\n",
    "        num_image = 0\n",
    "    return num_image\n",
    "\n",
    "train_data['num_image'] = [get_num_image(id) for id in train_data['id']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N_aFnq_xGl9t"
   },
   "outputs": [],
   "source": [
    "# Get more feature from timestamp\n",
    "\n",
    "from datetime import datetime \n",
    "\n",
    "train_data['datetime'] = pd.to_datetime([datetime.fromtimestamp(timestamp)  for timestamp in train_data['timestamp_post']]) \n",
    "\n",
    "train_data[\"minute in hour\"] = [x.minute for x in train_data[\"datetime\"].dt.time]\n",
    "train_data[\"hour in day\"] = [x.hour for x in train_data[\"datetime\"].dt.time]\n",
    "train_data[\"day in month\"] = [x.day for x in train_data[\"datetime\"].dt.date]\n",
    "train_data[\"quarter in year\"] = [x.month % 4 for x in train_data[\"datetime\"].dt.date]\n",
    "train_data[\"month in year\"] = [x.month for x in train_data[\"datetime\"].dt.date]\n",
    "train_data[\"weekday\"] = [x.weekday() for x in train_data[\"datetime\"].dt.date]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1J8kGi6Gl9u"
   },
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iazt0zxPGl9u"
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "\n",
    "from pandas import set_option\n",
    "# from pandas.tools.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 785,
     "status": "ok",
     "timestamp": 1607485094157,
     "user": {
      "displayName": "Tùng Bùi",
      "photoUrl": "",
      "userId": "07889802812406437747"
     },
     "user_tz": -420
    },
    "id": "sPlMfx81Gl9u",
    "outputId": "152945b6-e903-4945-ac25-fe10905b7fcb"
   },
   "outputs": [],
   "source": [
    "train, valid = train_test_split(train_data, test_size=0.1, random_state=42)\n",
    "\n",
    "# Score user_name\n",
    "black_list_user = train.loc[train['label'].apply(lambda x: x == 1)].user_name.value_counts()\n",
    "\n",
    "black_list_user = black_list_user.to_dict()\n",
    "\n",
    "def get_score_username(user_name, black_list_user):\n",
    "    score = 10\n",
    "    if user_name in black_list_user:\n",
    "        score -= 5*black_list_user[user_name]\n",
    "        \n",
    "    return score\n",
    "\n",
    "# train['user_score'] = [get_score_username(user_name, black_list_user) for user_name in train['user_name']] \n",
    "# valid['user_score'] = [get_score_username(user_name, black_list_user) for user_name in valid['user_name']] \n",
    "\n",
    "X_train =  train.drop([\"label\", \"id\", \"user_name\", \"post_message\", \"datetime\", \"timestamp_post\"], axis=1)\n",
    "Y_train = train[\"label\"]\n",
    "\n",
    "X_valid =  valid.drop([\"label\", \"id\", \"user_name\", \"post_message\", \"datetime\", \"timestamp_post\"], axis=1)\n",
    "Y_valid = valid[\"label\"]\n",
    "\n",
    "mm_scaler = preprocessing.MinMaxScaler()\n",
    "X_train = mm_scaler.fit_transform(X_train)\n",
    "X_valid = mm_scaler.fit_transform(X_valid)\n",
    "\n",
    "lb_binary = preprocessing.LabelBinarizer()\n",
    "Y_train = lb_binary.fit_transform(Y_train)\n",
    "Y_valid = lb_binary.fit_transform(Y_valid)\n",
    "\n",
    "ros = RandomOverSampler(sampling_strategy=0.66, random_state=0)\n",
    "X_resampled, Y_resampled = ros.fit_resample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use base line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7gEM2vaWGl9w"
   },
   "outputs": [],
   "source": [
    "# Spot-Check Algorithms\n",
    "def GetBasedModel():\n",
    "    basedModels = []\n",
    "    basedModels.append(('LR'   , LogisticRegression()))\n",
    "    basedModels.append(('LDA'  , LinearDiscriminantAnalysis()))\n",
    "    basedModels.append(('KNN'  , KNeighborsClassifier()))\n",
    "    basedModels.append(('CART' , DecisionTreeClassifier()))\n",
    "    basedModels.append(('NB'   , GaussianNB()))\n",
    "    basedModels.append(('SVM'  , SVC()))\n",
    "    basedModels.append(('AB'   , AdaBoostClassifier()))\n",
    "    basedModels.append(('GBM'  , GradientBoostingClassifier()))\n",
    "    basedModels.append(('RF'   , RandomForestClassifier()))\n",
    "    basedModels.append(('ET'   , ExtraTreesClassifier()))\n",
    "    basedModels.append(('MLP'   , MLPClassifier()))\n",
    "    \n",
    "    return basedModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7l5Y-XTl85sX"
   },
   "outputs": [],
   "source": [
    "def BasedLine_resampled(X_train, y_train, X_test, y_test, models):\n",
    "\n",
    "    results = []\n",
    "    names = []\n",
    "    for name, model in models:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        cv_results = roc_auc_score(y_test, y_pred)\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        msg = \"%s: %f\" % (name, cv_results)\n",
    "        print(msg)\n",
    "        \n",
    "    return names, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7AAkJztDGl9w"
   },
   "outputs": [],
   "source": [
    "def BasedLine(X, y, models):\n",
    "    # Test options and evaluation metric\n",
    "    num_folds = 10\n",
    "    scoring = 'roc_auc'\n",
    "\n",
    "    results = []\n",
    "    names = []\n",
    "    for name, model in models:\n",
    "        kfold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "        cv_results = cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "        print(msg)\n",
    "        \n",
    "    return names, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11372,
     "status": "ok",
     "timestamp": 1607485114849,
     "user": {
      "displayName": "Tùng Bùi",
      "photoUrl": "",
      "userId": "07889802812406437747"
     },
     "user_tz": -420
    },
    "id": "YpKT6fylGl9w",
    "outputId": "aa4ce44e-43fd-4099-d970-cdc70832e895"
   },
   "outputs": [],
   "source": [
    "models = GetBasedModel()\n",
    "\n",
    "print(\"Use K Fold in cross_val_score ----------------------\")\n",
    "names, results = BasedLine(X_train, Y_train, models)\n",
    "print(\"Use train test split ---------------------------------\")\n",
    "names, results = BasedLine_resampled(X_resampled, Y_resampled, X_valid, Y_valid, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kg4f1IJTqHhw"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from numpy import hstack\n",
    "\n",
    "def get_stacking():\n",
    "    # define the base models\n",
    "    # level0 = GetBasedModel()\n",
    "    level0 = list()\n",
    "    # level0.append(('LR'   , LogisticRegression()))\n",
    "    # level0.append(('LDA'  , LinearDiscriminantAnalysis()))\n",
    "    level0.append(('KNN'  , KNeighborsClassifier()))\n",
    "    level0.append(('CART' , DecisionTreeClassifier()))\n",
    "    level0.append(('NB'   , GaussianNB()))\n",
    "    level0.append(('SVM'  , SVC()))\n",
    "    # level0.append(('AB'   , AdaBoostClassifier()))\n",
    "    level0.append(('GBM'  , GradientBoostingClassifier()))\n",
    "    level0.append(('RF'   , RandomForestClassifier()))\n",
    "    # level0.append(('ET'   , ExtraTreesClassifier()))\n",
    "    level0.append(('MLP'   , MLPClassifier()))\n",
    "    # define meta learner model\n",
    "    level1 = LogisticRegression()\n",
    "    # define the stacking ensemble\n",
    "    model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names,results = BasedLine2(X_resampled, Y_resampled, [('stacking', get_stacking())])\n",
    "\n",
    "names,results = BasedLine1(X_resampled, Y_resampled, X_valid, Y_valid, [('stacking', get_stacking())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blending(models, X_train, X_val, y_train, y_val):\n",
    "    # fit all models on the training set and predict on hold out set\n",
    "    meta_X = list()\n",
    "    for name, model in models:\n",
    "        # fit in training set\n",
    "        model.fit(X_train, y_train)\n",
    "        # predict on hold out set\n",
    "        yhat = model.predict(X_val)\n",
    "        # reshape predictions into a matrix with one column\n",
    "        yhat = yhat.reshape(len(yhat), 1)\n",
    "        # store predictions as input for blending\n",
    "        meta_X.append(yhat)\n",
    "    # create 2d array from predictions, each set is an input feature\n",
    "    meta_X = hstack(meta_X)\n",
    "    # define blending model\n",
    "    blender = LogisticRegression()\n",
    "    # fit on predictions from base models\n",
    "    blender.fit(meta_X, y_val)\n",
    "    return blender\n",
    "\n",
    "# make a prediction with the blending ensemble\n",
    "def predict_ensemble(models, blender, X_test):\n",
    "    # make predictions with base models\n",
    "    meta_X = list()\n",
    "    for name, model in models:\n",
    "        # predict with base model\n",
    "        yhat = model.predict(X_test)\n",
    "        # reshape predictions into a matrix with one column\n",
    "        yhat = yhat.reshape(len(yhat), 1)\n",
    "        # store prediction\n",
    "        meta_X.append(yhat)\n",
    "    # create 2d array from predictions, each set is an input feature\n",
    "    meta_X = hstack(meta_X)\n",
    "    # predict\n",
    "    return blender.predict(meta_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8432,
     "status": "ok",
     "timestamp": 1607485739433,
     "user": {
      "displayName": "Tùng Bùi",
      "photoUrl": "",
      "userId": "07889802812406437747"
     },
     "user_tz": -420
    },
    "id": "uUQmxq2MqHWS",
    "outputId": "59eaca86-45df-415d-9ec2-6300f2ec6680"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_resampled, Y_resampled, test_size=0.33, random_state=1)\n",
    "\n",
    "# create the base models\n",
    "models = GetBasedModel()\n",
    "# train the blending ensemble\n",
    "blender = blending(models, X_train, X_val, y_train, y_val)\n",
    "# make predictions on test set\n",
    "yhat = predict_ensemble(models, blender, X_valid)\n",
    "# evaluate predictions\n",
    "score = roc_auc_score(Y_valid, yhat)\n",
    "print('Blending ROC_AUC: %.3f' % (score*100))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "_qOb-ltWGl97",
    "--_1r506Gl9_"
   ],
   "name": "EDA.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
